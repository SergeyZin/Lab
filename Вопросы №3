1. Перечислите возможные гиперпараметры модели линейной регрессии.
  Модель линейной регрессии имеет несколько гиперпараметров, которые можно настроить для улучшения производительности модели. Вот некоторые из наиболее распространенных гиперпараметров:
  Регуляризация:
  Коэффициент регуляризации (альфа, alpha): Определяет степень регуляризации, которая применяется к коэффициентам модели. Более высокие значения альфа приводят к более сильной регуляризации и меньшим коэффициентам.
  Тип регуляризации (L1 или L2): L1 (лассо) регуляризация приводит к разреженным моделям, а L2 (гребневая) регуляризация сжимает коэффициенты к нулю, но не обнуляет их полностью.
  Нормализация данных:
  Нормализация признаков (True/False): Определяет, должны ли признаки быть нормализованы (приведены к одному масштабу) перед обучением модели.
  Решение недоопределенных задач:
  Допустимая доля отрицательных значений (negative_tolerance): Определяет допустимую долю отрицательных значений при решении недоопределенных задач.
  Численная стабильность:
  Параметр численной стабильности (eps): Небольшое положительное число, добавляемое к диагональным элементам матрицы для улучшения численной стабильности.
  Оптимизация:
  Максимальное количество итераций (max_iter): Максимальное количество итераций, которое будет использовано для оптимизации коэффициентов модели.
  Допустимая ошибка (tol): Допустимая ошибка для остановки оптимизации.
  Обработка категориальных признаков:
  Стратегия кодирования категориальных признаков (one-hot, ordinal, и т.д.): Определяет, как категориальные признаки должны быть закодированы перед обучением модели.

2.Может ли коэффициент детерминации быть отрицательным числом?
  Да, коэффициент детерминации (R-квадрат) может принимать отрицательные значения, хотя это случается довольно редко.
  Коэффициент детерминации - это метрика, которая показывает, насколько хорошо модель объясняет вариацию зависимой переменной. Его значения лежат в диапазоне от 0 до 1, где 1 означает идеальное соответствие модели данным, а 0 означает, что модель не объясняет вариацию зависимой переменной.

3. Оцените MSE для следующих данных: реальные значения y {1, 2, 3, 4}, предсказания модели y  {2, 1, 4, 6}.
  Чтобы оценить MSE (среднеквадратичную ошибку) для заданных реальных значений y и предсказаний модели ŷ, нужно выполнить следующие шаги:
  Вычислить разность между реальными значениями y и предсказаниями ŷ для каждого примера:
  (1 - 2) = -1
  (2 - 1) = 1
  (3 - 4) = -1
  (4 - 6) = -2
  Возвести каждую разность в квадрат:
  (-1)^2 = 1
  1^2 = 1
  (-1)^2 = 1
  (-2)^2 = 4
  Найти сумму квадратов разностей:
  1 + 1 + 1 + 4 = 7
  Разделить сумму квадратов разностей на количество примеров n:
  MSE = 7 / 4 = 1.75
  Таким образом, MSE (среднеквадратичная ошибка) для заданных реальных значений y = {1, 2, 3, 4} и предсказаний модели ŷ = {2, 1, 4, 6} равна 1.75.

4. Предположим, что у вас есть вектор весов w {10, 5, 6}. Вы посчитали градиент функции потерь, который равен {20, −10, 40}. Посчитайте обновленный вектор весов при условии, что скорость обучения составляет 0.1.
  w_new = w_old - learning_rate * gradient
  Где:
  w_new - обновленный вектор весов
  w_old - текущий вектор весов
  learning_rate - скорость обучения
  gradient - градиент функции потерь
  Дано:
  Текущий вектор весов w = {10, 5, 6}
  Градиент функции потерь = {20, -10, 40}
  Скорость обучения (learning_rate) = 0.1
  Подставляем значения в формулу обновления весов:
  w_new[0] = w_old[0] - learning_rate * gradient[0] = 10 - 0.1 * 20 = 10 - 2 = 8
  w_new[1] = w_old[1] - learning_rate * gradient[1] = 5 - 0.1 * (-10) = 5 + 1 = 6
  w_new[2] = w_old[2] - learning_rate * gradient[2] = 6 - 0.1 * 40 = 6 - 4 = 2
Таким образом, обновленный вектор весов w_new = {8, 6, 2}.

5. Перечислите данные, которые вам необходимы для расчета градиента функции потерь.
  Для расчета градиента функции потерь в задачах машинного обучения необходимы следующие данные:
  Обучающие примеры (X, y):
  X - матрица признаков, где каждая строка представляет один обучающий пример
  y - вектор целевых значений (меток классов или значений для регрессии)
  Текущие веса модели (w):
  Вектор весов, который определяет текущие параметры модели
  Предсказания модели (ŷ):
  Предсказания, полученные на основе текущих весов модели и обучающих примеров
  Функция потерь (loss function):
  Функция, которая измеряет расхождение между предсказаниями модели и истинными целевыми значениями
  Градиент функции потерь представляет собой вектор частных производных функции потерь по каждому весу модели. Для его вычисления необходимы:
  Частные производные функции потерь по каждому весу:
  Эти производные показывают, как изменяется функция потерь при небольшом изменении соответствующего веса

6. Вы выполнили обучение линейной модели дважды: с регуляризацией и без. У вас есть два вектора весов модели w1 {14.37, 22.80, 32.20} и w2 {0.69, 2.02, 4.20}, но вы не помните, какой вектор весов какой модели соответствует. Как вы считаете, который из приведенных весов соответствует случаю регуляризации?
  Сравнивая абсолютные значения весов в двух векторах:
  w1 = {14.37, 22.80, 32.20}
  w2 = {0.69, 2.02, 4.20}
  Мы видим, что веса в векторе w2 имеют гораздо меньшие абсолютные значения, чем веса в векторе w1.
  Таким образом, с высокой долей вероятности вектор весов w2 = {0.69, 2.02, 4.20} соответствует случаю с регуляризацией, поскольку регуляризация обычно приводит к меньшим абсолютным значениям весов.
  А вектор весов w1 = {14.37, 22.80, 32.20} с большими абсолютными значениями, скорее всего, соответствует случаю без регуляризации.

7. Вы получили веса модели w {3, −2, 2}. В модели не используется смещение. Оцените предсказание модели для следующих значений параметров x {1, 3, 1}
  Чтобы оценить предсказание линейной модели без смещения для заданных значений параметров x = {1, 3, 1}, нужно выполнить скалярное произведение вектора весов w и вектора параметров x.
  Формула для предсказания линейной модели без смещения:
  ŷ = w_1 * x_1 + w_2 * x_2 + ... + w_n * x_n
  Где:
  ŷ - предсказанное значение
  w_i - вес i-го параметра
  x_i - значение i-го параметра
  Дано:
  Вектор весов w = {3, -2, 2}
  Вектор параметров x = {1, 3, 1}
  Подставляем значения в формулу:
  ŷ = 3 * 1 + (-2) * 3 + 2 * 1
  ŷ = 3 + (-6) + 2
  ŷ = -1
  Таким образом, предсказание линейной модели без смещения с весами w = {3, -2, 2} для вектора параметров x = {1, 3, 1} равно -1.

8. Оцените коэффициент детерминации для следующих данных:
  реальные значения y {1, 2, 3, 4}, 
  предсказания модели y - y' {2, 1, 4, 6}.
  Чтобы оценить коэффициент детерминации (R-квадрат) для заданных реальных значений y и предсказаний модели ŷ, нужно выполнить следующие шаги:
  Вычислить среднее значение реальных значений y:
  mean(y) = (1 + 2 + 3 + 4) / 4 = 2.5
  Вычислить сумму квадратов отклонений реальных значений от среднего (TSS - Total Sum of Squares):
  TSS = Σ(y_i - mean(y))^2
  TSS = (1 - 2.5)^2 + (2 - 2.5)^2 + (3 - 2.5)^2 + (4 - 2.5)^2 = 7.5
  Вычислить сумму квадратов остатков (RSS - Residual Sum of Squares):
  RSS = Σ(y_i - ŷ_i)^2
  RSS = (1 - 2)^2 + (2 - 1)^2 + (3 - 4)^2 + (4 - 6)^2 = 7
  Коэффициент детерминации R-квадрат вычисляется по формуле:
  R^2 = 1 - RSS / TSS
  Подставляем значения:
  R^2 = 1 - 7 / 7.5 = 0.0667
  Таким образом, коэффициент детерминации для заданных реальных значений y = {1, 2, 3, 4} и предсказаний модели ŷ = {2, 1, 4, 6} равен 0.0667 или приблизительно 6.67%.
